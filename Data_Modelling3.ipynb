{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f83e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\ayu sekar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ayu sekar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f9b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce55936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataset_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37266323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3983 entries, 1970-01-01 00:00:00 to 1970-01-01 00:00:00.000003982\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   TANGGAL      3983 non-null   datetime64[ns]\n",
      " 1   TN           3983 non-null   float64       \n",
      " 2   TX           3983 non-null   float64       \n",
      " 3   TAVG         3983 non-null   float64       \n",
      " 4   RH_AVG       3983 non-null   float64       \n",
      " 5   RR           3983 non-null   float64       \n",
      " 6   SS           3983 non-null   float64       \n",
      " 7   FF_X         3983 non-null   int64         \n",
      " 8   DDD_X        3983 non-null   int64         \n",
      " 9   FF_AVG       3983 non-null   int64         \n",
      " 10  DDD_CAR      3983 non-null   int64         \n",
      " 11  Bulan_Angka  3983 non-null   int32         \n",
      " 12  Bulan_Sin    3983 non-null   float64       \n",
      " 13  Bulan_Cos    3983 non-null   float64       \n",
      " 14  RR_lag1      3982 non-null   float64       \n",
      " 15  RR_lag2      3981 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10), int32(1), int64(4)\n",
      "memory usage: 513.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d7b17",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801aa389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bulan_Angka\n",
      "1970-01-01 00:00:00.000000000            1\n",
      "1970-01-01 00:00:00.000000001            1\n",
      "1970-01-01 00:00:00.000000002            1\n",
      "1970-01-01 00:00:00.000000003            1\n",
      "1970-01-01 00:00:00.000000004            1\n"
     ]
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Bulan_Angka'] = df.index.month\n",
    "\n",
    "print(df[['Bulan_Angka']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0fd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bulan_Angka  Bulan_Sin  Bulan_Cos\n",
      "1970-01-01 00:00:00.000000000            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000001            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000002            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000003            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000004            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000005            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000006            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000007            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000008            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000009            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000010            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000011            1        0.5   0.866025\n"
     ]
    }
   ],
   "source": [
    "# Buat Fitur Sinus (Sumbu Y)\n",
    "df['Bulan_Sin'] = np.sin(2 * np.pi * df['Bulan_Angka'] / 12)\n",
    "\n",
    "# Buat Fitur Cosinus (Sumbu X)\n",
    "df['Bulan_Cos'] = np.cos(2 * np.pi * df['Bulan_Angka'] / 12)\n",
    "\n",
    "# Lihat hasilnya\n",
    "print(df[['Bulan_Angka', 'Bulan_Sin', 'Bulan_Cos']].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dc92643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 RR  RR_lag1  RR_lag2\n",
      "1970-01-01 00:00:00.000000000  14.5      NaN      NaN\n",
      "1970-01-01 00:00:00.000000001  31.5     14.5      NaN\n",
      "1970-01-01 00:00:00.000000002   0.5     31.5     14.5\n",
      "1970-01-01 00:00:00.000000003   2.4      0.5     31.5\n",
      "1970-01-01 00:00:00.000000004  35.3      2.4      0.5\n"
     ]
    }
   ],
   "source": [
    "# Pastikan data urut berdasarkan tanggal dulu! (Wajib)\n",
    "df = df.sort_index()\n",
    "\n",
    "# --- MEMBUAT LAG FEATURES ---\n",
    "\n",
    "# 1. Fitur: Curah Hujan Kemarin (H-1)\n",
    "df['RR_lag1'] = df['RR'].shift(1)\n",
    "\n",
    "# 2. Fitur: Curah Hujan 2 Hari Lalu (H-2)\n",
    "df['RR_lag2'] = df['RR'].shift(2)\n",
    "\n",
    "# 3. Fitur: Kelembapan Kemarin (H-1)\n",
    "# Karena kelembapan kemarin sangat mempengaruhi jenuhnya awan hari ini\n",
    "df['RH_lag1'] = df['RH_AVG'].shift(1)\n",
    "\n",
    "# --- CEK HASILNYA ---\n",
    "# Kita lihat 5 baris pertama\n",
    "# Perhatikan ada nilai NaN (Not a Number)\n",
    "print(df[['RR', 'RR_lag1', 'RR_lag2']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "882ae3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data awal: 3983 baris\n",
      "Data setelah dropna: 3981 baris\n"
     ]
    }
   ],
   "source": [
    "# Hapus baris yang mengandung NaN akibat shift\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"Data awal: {len(df)} baris\")\n",
    "print(f\"Data setelah dropna: {len(df_clean)} baris\")\n",
    "# Biasanya berkurang 2 baris (karena lag terjauh kita adalah 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9598ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   RR  RR_mean_7d\n",
      "1970-01-01 00:00:00.000000000  14.500         NaN\n",
      "1970-01-01 00:00:00.000000001  31.500         NaN\n",
      "1970-01-01 00:00:00.000000002   0.500         NaN\n",
      "1970-01-01 00:00:00.000000003   2.400         NaN\n",
      "1970-01-01 00:00:00.000000004  35.300         NaN\n",
      "1970-01-01 00:00:00.000000005   2.300         NaN\n",
      "1970-01-01 00:00:00.000000006   0.000         NaN\n",
      "1970-01-01 00:00:00.000000007   0.329   12.357143\n",
      "1970-01-01 00:00:00.000000008   0.275   10.332714\n",
      "1970-01-01 00:00:00.000000009   0.154    5.872000\n"
     ]
    }
   ],
   "source": [
    "# Pastikan data urut waktu\n",
    "df = df.sort_index()\n",
    "\n",
    "# --- FITUR ROLLING WINDOW ---\n",
    "\n",
    "# 1. Rata-rata Hujan 7 Hari Terakhir\n",
    "# .rolling(7).mean() -> Hitung rata-rata per blok 7 hari\n",
    "# .shift(1) -> GESER ke bawah, supaya data hari ini tidak ikut kehitung\n",
    "df['RR_mean_7d'] = df['RR'].rolling(window=7).mean().shift(1)\n",
    "\n",
    "# 2. Rata-rata Kelembapan 3 Hari Terakhir\n",
    "df['RH_mean_3d'] = df['RH_AVG'].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# 3. Maksimum Angin 3 Hari Terakhir (Mendeteksi badai yg baru lewat)\n",
    "df['ff_max_3d'] = df['FF_X'].rolling(window=3).max().shift(1)\n",
    "\n",
    "# --- CEK HASILNYA ---\n",
    "print(df[['RR', 'RR_mean_7d']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "850be2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data siap pakai: 3976 baris\n"
     ]
    }
   ],
   "source": [
    "# Hapus baris NaN di awal data\n",
    "df_final = df.dropna()\n",
    "\n",
    "print(f\"Data siap pakai: {len(df_final)} baris\")\n",
    "# Data Anda sekarang sudah bersih, padat, dan kaya fitur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b922277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering Fisika Selesai.\n",
      "                                 TX    TN  Temp_Range    Wind_x    Wind_y\n",
      "1970-01-01 00:00:00.000000000  29.8  23.6         6.2  3.064178 -2.571150\n",
      "1970-01-01 00:00:00.000000001  29.4  24.2         5.2  3.064178 -2.571150\n",
      "1970-01-01 00:00:00.000000002  29.6  25.0         4.6  4.316039 -4.167950\n",
      "1970-01-01 00:00:00.000000003  30.0  24.4         5.6  3.596699 -3.473292\n",
      "1970-01-01 00:00:00.000000004  32.6  24.0         8.6  2.925415 -2.727993\n"
     ]
    }
   ],
   "source": [
    "# --- 1. FITUR SELISIH SUHU (DETEKTOR AWAN) ---\n",
    "# Tx = Suhu Maksimum, Tn = Suhu Minimum\n",
    "df['Temp_Range'] = df['TX'] - df['TN']\n",
    "\n",
    "\n",
    "# --- 2. FITUR VEKTOR ANGIN ---\n",
    "# Kita butuh kecepatan (ff_x) dan arah (ddd_x)\n",
    "\n",
    "# Langkah A: Ubah derajat ke Radian (Komputer maunya Radian)\n",
    "# Rumus: Derajat * PI / 180\n",
    "wd_rad = df['DDD_X'] * np.pi / 180\n",
    "\n",
    "# Langkah B: Hitung Komponen X dan Y\n",
    "# Angin X (Barat <-> Timur)\n",
    "df['Wind_x'] = df['FF_X'] * np.cos(wd_rad)\n",
    "\n",
    "# Angin Y (Selatan <-> Utara)\n",
    "df['Wind_y'] = df['FF_X'] * np.sin(wd_rad)\n",
    "\n",
    "# --- FINAL CHECK ---\n",
    "# Hapus kolom asli yang sudah tidak dipakai (opsional, biar rapi)\n",
    "# Kita drop 'ddd_x' karena sudah diganti Wind_x dan Wind_y\n",
    "# df = df.drop(columns=['ddd_x']) \n",
    "\n",
    "print(\"Engineering Fisika Selesai.\")\n",
    "print(df[['TX', 'TN', 'Temp_Range', 'Wind_x', 'Wind_y']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d414101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom numerik: ['TN', 'TX', 'TAVG', 'RH_AVG', 'RR', 'SS', 'FF_X', 'DDD_X', 'FF_AVG', 'DDD_CAR', 'BULAN_ANGKA', 'BULAN_SIN', 'BULAN_COS', 'RR_LAG1', 'RR_LAG2', 'RH_LAG1', 'RR_MEAN_7D', 'RH_MEAN_3D', 'FF_MAX_3D', 'TEMP_RANGE', 'WIND_X', 'WIND_Y']\n",
      "Train: (3983, 21)\n",
      "Val  : (0, 21)\n",
      "Test : (0, 21)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required by SimpleImputer.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m cols = X.columns\n\u001b[32m     66\u001b[39m X_train_imp = pd.DataFrame(imputer.transform(X_train), columns=cols, index=X_train.index)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m X_val_imp   = pd.DataFrame(\u001b[43mimputer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m,   columns=cols, index=X_val.index)\n\u001b[32m     68\u001b[39m X_test_imp  = pd.DataFrame(imputer.transform(X_test),  columns=cols, index=X_test.index)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 5. SCALING\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:609\u001b[39m, in \u001b[36mSimpleImputer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Impute all missing values in `X`.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    605\u001b[39m \u001b[33;03m    `X` with imputed values.\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    607\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m statistics = \u001b[38;5;28mself\u001b[39m.statistics_\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m1\u001b[39m] != statistics.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:363\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_fit:\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_dtype = X.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:344\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    341\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required by SimpleImputer."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ==========================================\n",
    "# 0. CLEANING AWAL\n",
    "# ==========================================\n",
    "\n",
    "# Rapikan nama kolom\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# Pastikan index datetime\n",
    "# df['TANGGAL'] = pd.to_datetime(df['TANGGAL'])  # aktifkan jika tanggal masih string\n",
    "# df = df.set_index('TANGGAL')                   # aktifkan jika index belum tanggal\n",
    "df = df.sort_index()\n",
    "\n",
    "# Pastikan target ada\n",
    "target_col = \"RR\"\n",
    "if target_col not in df.columns:\n",
    "    raise Exception(f\"Target '{target_col}' tidak ditemukan. Kolom tersedia:\\n{df.columns.tolist()}\")\n",
    "\n",
    "# Pastikan target numerik\n",
    "df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "\n",
    "# ==========================================\n",
    "# 1. AMBIL HANYA KOLOM NUMERIK\n",
    "# ==========================================\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Kolom numerik:\", df_numeric.columns.tolist())\n",
    "\n",
    "# ==========================================\n",
    "# 2. FITUR DAN TARGET\n",
    "# ==========================================\n",
    "X = df_numeric.drop(columns=[target_col], errors=\"ignore\")\n",
    "y = df_numeric[target_col]\n",
    "\n",
    "# ==========================================\n",
    "# 3. TIME SERIES SPLIT\n",
    "# ==========================================\n",
    "train_end = '2022-12-31'\n",
    "val_end   = '2023-12-31'\n",
    "\n",
    "X_train = X.loc[:train_end]\n",
    "y_train = y.loc[:train_end]\n",
    "\n",
    "X_val = X.loc['2023-01-01':val_end]\n",
    "y_val = y.loc['2023-01-01':val_end]\n",
    "\n",
    "X_test = X.loc['2024-01-01':]\n",
    "y_test = y.loc['2024-01-01':]\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val  :\", X_val.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "# ==========================================\n",
    "# 4. IMPUTATION\n",
    "# ==========================================\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(X_train)\n",
    "\n",
    "cols = X.columns\n",
    "\n",
    "X_train_imp = pd.DataFrame(imputer.transform(X_train), columns=cols, index=X_train.index)\n",
    "X_val_imp   = pd.DataFrame(imputer.transform(X_val),   columns=cols, index=X_val.index)\n",
    "X_test_imp  = pd.DataFrame(imputer.transform(X_test),  columns=cols, index=X_test.index)\n",
    "\n",
    "# ==========================================\n",
    "# 5. SCALING\n",
    "# ==========================================\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_imp)\n",
    "\n",
    "X_train_final = pd.DataFrame(scaler.transform(X_train_imp), columns=cols, index=X_train.index)\n",
    "X_val_final   = pd.DataFrame(scaler.transform(X_val_imp),   columns=cols, index=X_val.index)\n",
    "X_test_final  = pd.DataFrame(scaler.transform(X_test_imp),  columns=cols, index=X_test.index)\n",
    "\n",
    "print(\"\\nSUKSES! Semua data sudah siap dipakai untuk model.\")\n",
    "print(X_train_final.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cf312c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TANGGAL', 'TN', 'TX', 'TAVG', 'RH_AVG', 'RR', 'SS', 'FF_X', 'DDD_X', 'FF_AVG', 'DDD_CAR', 'BULAN_ANGKA', 'BULAN_SIN', 'BULAN_COS', 'RR_LAG1', 'RR_LAG2', 'RH_LAG1', 'RR_MEAN_7D', 'RH_MEAN_3D', 'FF_MAX_3D', 'TEMP_RANGE', 'WIND_X', 'WIND_Y']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
