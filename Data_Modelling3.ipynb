{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f83e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\ayu sekar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ayu sekar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f9b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce55936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataset_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37266323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3983 entries, 0 to 3982\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   TANGGAL  3983 non-null   datetime64[ns]\n",
      " 1   TN       3983 non-null   float64       \n",
      " 2   TX       3983 non-null   float64       \n",
      " 3   TAVG     3983 non-null   float64       \n",
      " 4   RH_AVG   3983 non-null   float64       \n",
      " 5   RR       3983 non-null   float64       \n",
      " 6   SS       3983 non-null   float64       \n",
      " 7   FF_X     3983 non-null   int64         \n",
      " 8   DDD_X    3983 non-null   int64         \n",
      " 9   FF_AVG   3983 non-null   int64         \n",
      " 10  DDD_CAR  3983 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(4)\n",
      "memory usage: 342.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d7b17",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801aa389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bulan_Angka\n",
      "1970-01-01 00:00:00.000000000            1\n",
      "1970-01-01 00:00:00.000000001            1\n",
      "1970-01-01 00:00:00.000000002            1\n",
      "1970-01-01 00:00:00.000000003            1\n",
      "1970-01-01 00:00:00.000000004            1\n"
     ]
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Bulan_Angka'] = df.index.month\n",
    "\n",
    "print(df[['Bulan_Angka']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0fd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bulan_Angka  Bulan_Sin  Bulan_Cos\n",
      "1970-01-01 00:00:00.000000000            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000001            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000002            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000003            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000004            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000005            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000006            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000007            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000008            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000009            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000010            1        0.5   0.866025\n",
      "1970-01-01 00:00:00.000000011            1        0.5   0.866025\n"
     ]
    }
   ],
   "source": [
    "# Buat Fitur Sinus (Sumbu Y)\n",
    "df['Bulan_Sin'] = np.sin(2 * np.pi * df['Bulan_Angka'] / 12)\n",
    "\n",
    "# Buat Fitur Cosinus (Sumbu X)\n",
    "df['Bulan_Cos'] = np.cos(2 * np.pi * df['Bulan_Angka'] / 12)\n",
    "\n",
    "# Lihat hasilnya\n",
    "print(df[['Bulan_Angka', 'Bulan_Sin', 'Bulan_Cos']].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc92643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 RR  RR_lag1  RR_lag2\n",
      "1970-01-01 00:00:00.000000000  14.5      NaN      NaN\n",
      "1970-01-01 00:00:00.000000001  31.5     14.5      NaN\n",
      "1970-01-01 00:00:00.000000002   0.5     31.5     14.5\n",
      "1970-01-01 00:00:00.000000003   2.4      0.5     31.5\n",
      "1970-01-01 00:00:00.000000004  35.3      2.4      0.5\n"
     ]
    }
   ],
   "source": [
    "# Pastikan data urut berdasarkan tanggal dulu! (Wajib)\n",
    "df = df.sort_index()\n",
    "\n",
    "# --- MEMBUAT LAG FEATURES ---\n",
    "\n",
    "# 1. Fitur: Curah Hujan Kemarin (H-1)\n",
    "df['RR_lag1'] = df['RR'].shift(1)\n",
    "\n",
    "# 2. Fitur: Curah Hujan 2 Hari Lalu (H-2)\n",
    "df['RR_lag2'] = df['RR'].shift(2)\n",
    "\n",
    "# 3. Fitur: Kelembapan Kemarin (H-1)\n",
    "# Karena kelembapan kemarin sangat mempengaruhi jenuhnya awan hari ini\n",
    "df['RH_lag1'] = df['RH_AVG'].shift(1)\n",
    "\n",
    "# --- CEK HASILNYA ---\n",
    "# Kita lihat 5 baris pertama\n",
    "# Perhatikan ada nilai NaN (Not a Number)\n",
    "print(df[['RR', 'RR_lag1', 'RR_lag2']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882ae3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data awal: 3983 baris\n",
      "Data setelah dropna: 3981 baris\n"
     ]
    }
   ],
   "source": [
    "# Hapus baris yang mengandung NaN akibat shift\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"Data awal: {len(df)} baris\")\n",
    "print(f\"Data setelah dropna: {len(df_clean)} baris\")\n",
    "# Biasanya berkurang 2 baris (karena lag terjauh kita adalah 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9598ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   RR  RR_mean_7d\n",
      "1970-01-01 00:00:00.000000000  14.500         NaN\n",
      "1970-01-01 00:00:00.000000001  31.500         NaN\n",
      "1970-01-01 00:00:00.000000002   0.500         NaN\n",
      "1970-01-01 00:00:00.000000003   2.400         NaN\n",
      "1970-01-01 00:00:00.000000004  35.300         NaN\n",
      "1970-01-01 00:00:00.000000005   2.300         NaN\n",
      "1970-01-01 00:00:00.000000006   0.000         NaN\n",
      "1970-01-01 00:00:00.000000007   0.329   12.357143\n",
      "1970-01-01 00:00:00.000000008   0.275   10.332714\n",
      "1970-01-01 00:00:00.000000009   0.154    5.872000\n"
     ]
    }
   ],
   "source": [
    "# Pastikan data urut waktu\n",
    "df = df.sort_index()\n",
    "\n",
    "# --- FITUR ROLLING WINDOW ---\n",
    "\n",
    "# 1. Rata-rata Hujan 7 Hari Terakhir\n",
    "# .rolling(7).mean() -> Hitung rata-rata per blok 7 hari\n",
    "# .shift(1) -> GESER ke bawah, supaya data hari ini tidak ikut kehitung\n",
    "df['RR_mean_7d'] = df['RR'].rolling(window=7).mean().shift(1)\n",
    "\n",
    "# 2. Rata-rata Kelembapan 3 Hari Terakhir\n",
    "df['RH_mean_3d'] = df['RH_AVG'].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# 3. Maksimum Angin 3 Hari Terakhir (Mendeteksi badai yg baru lewat)\n",
    "df['ff_max_3d'] = df['FF_X'].rolling(window=3).max().shift(1)\n",
    "\n",
    "# --- CEK HASILNYA ---\n",
    "print(df[['RR', 'RR_mean_7d']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "850be2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data siap pakai: 3976 baris\n"
     ]
    }
   ],
   "source": [
    "# Hapus baris NaN di awal data\n",
    "df_final = df.dropna()\n",
    "\n",
    "print(f\"Data siap pakai: {len(df_final)} baris\")\n",
    "# Data Anda sekarang sudah bersih, padat, dan kaya fitur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b922277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering Fisika Selesai.\n",
      "                                 TX    TN  Temp_Range    Wind_x    Wind_y\n",
      "1970-01-01 00:00:00.000000000  29.8  23.6         6.2  3.064178 -2.571150\n",
      "1970-01-01 00:00:00.000000001  29.4  24.2         5.2  3.064178 -2.571150\n",
      "1970-01-01 00:00:00.000000002  29.6  25.0         4.6  4.316039 -4.167950\n",
      "1970-01-01 00:00:00.000000003  30.0  24.4         5.6  3.596699 -3.473292\n",
      "1970-01-01 00:00:00.000000004  32.6  24.0         8.6  2.925415 -2.727993\n"
     ]
    }
   ],
   "source": [
    "# --- 1. FITUR SELISIH SUHU (DETEKTOR AWAN) ---\n",
    "# Tx = Suhu Maksimum, Tn = Suhu Minimum\n",
    "df['Temp_Range'] = df['TX'] - df['TN']\n",
    "\n",
    "\n",
    "# --- 2. FITUR VEKTOR ANGIN ---\n",
    "# Kita butuh kecepatan (ff_x) dan arah (ddd_x)\n",
    "\n",
    "# Langkah A: Ubah derajat ke Radian (Komputer maunya Radian)\n",
    "# Rumus: Derajat * PI / 180\n",
    "wd_rad = df['DDD_X'] * np.pi / 180\n",
    "\n",
    "# Langkah B: Hitung Komponen X dan Y\n",
    "# Angin X (Barat <-> Timur)\n",
    "df['Wind_x'] = df['FF_X'] * np.cos(wd_rad)\n",
    "\n",
    "# Angin Y (Selatan <-> Utara)\n",
    "df['Wind_y'] = df['FF_X'] * np.sin(wd_rad)\n",
    "\n",
    "# --- FINAL CHECK ---\n",
    "# Hapus kolom asli yang sudah tidak dipakai (opsional, biar rapi)\n",
    "# Kita drop 'ddd_x' karena sudah diganti Wind_x dan Wind_y\n",
    "# df = df.drop(columns=['ddd_x']) \n",
    "\n",
    "print(\"Engineering Fisika Selesai.\")\n",
    "print(df[['TX', 'TN', 'Temp_Range', 'Wind_x', 'Wind_y']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d414101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85aa0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"RR\"   # variabel yang mau diprediksi\n",
    "\n",
    "# Hanya ambil kolom numerik\n",
    "df_num = df_final.select_dtypes(include=[np.number])\n",
    "\n",
    "X = df_num.drop(columns=[target_col])   # fitur\n",
    "y = df_num[target_col]                  # target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2721db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = '2022-12-31'\n",
    "val_end   = '2023-12-31'\n",
    "\n",
    "X_train = X.loc[:train_end]\n",
    "y_train = y.loc[:train_end]\n",
    "\n",
    "X_val = X.loc['2023-01-01':val_end]\n",
    "y_val = y.loc['2023-01-01':val_end]\n",
    "\n",
    "X_test = X.loc['2024-01-01':]\n",
    "y_test = y.loc['2024-01-01':]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4c4452",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m cols = X_train.columns\n\u001b[32m     10\u001b[39m X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=cols, index=X_train.index)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m X_val_scaled   = pd.DataFrame(\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m,   columns=cols, index=X_val.index)\n\u001b[32m     12\u001b[39m X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=cols, index=X_test.index)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSUKSES! Split & scaling selesai tanpa data leakage.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:545\u001b[39m, in \u001b[36mMinMaxScaler.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    541\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    543\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_array_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m X *= \u001b[38;5;28mself\u001b[39m.scale_\n\u001b[32m    556\u001b[39m X += \u001b[38;5;28mself\u001b[39m.min_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit hanya pada train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=cols, index=X_train.index)\n",
    "X_val_scaled   = pd.DataFrame(scaler.transform(X_val),   columns=cols, index=X_val.index)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=cols, index=X_test.index)\n",
    "\n",
    "print(\"SUKSES! Split & scaling selesai tanpa data leakage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6e0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TANGGAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'TANGGAL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. LOAD DATA (PASTIKAN NAMA SESUAI FILE KAMU)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Contoh: df = pd.read_csv(\"cuaca.csv\")\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Asumsi: kolom TANGGAL adalah kolom datetime\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTANGGAL\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTANGGAL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     14\u001b[39m df = df.set_index(\u001b[33m'\u001b[39m\u001b[33mTANGGAL\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData awal:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayu Sekar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'TANGGAL'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
