{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21d47f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f1b8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2c8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataset_final.xlsx\", parse_dates=['TANGGAL'])\n",
    "df = df.sort_values('TANGGAL')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd391d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3983 entries, 0 to 3982\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   TANGGAL  3983 non-null   datetime64[ns]\n",
      " 1   TN       3983 non-null   float64       \n",
      " 2   TX       3983 non-null   float64       \n",
      " 3   TAVG     3983 non-null   float64       \n",
      " 4   RH_AVG   3983 non-null   float64       \n",
      " 5   RR       3983 non-null   float64       \n",
      " 6   SS       3983 non-null   float64       \n",
      " 7   FF_X     3983 non-null   int64         \n",
      " 8   DDD_X    3983 non-null   int64         \n",
      " 9   FF_AVG   3983 non-null   int64         \n",
      " 10  DDD_CAR  3983 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(4)\n",
      "memory usage: 342.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98677859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_safe_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Date components\n",
    "    df['month'] = df['TANGGAL'].dt.month\n",
    "    df['day']   = df['TANGGAL'].dt.day\n",
    "\n",
    "    df['month_sin'] = np.sin(2*np.pi*df['month']/12)\n",
    "    df['month_cos'] = np.cos(2*np.pi*df['month']/12)\n",
    "    df['day_sin']   = np.sin(2*np.pi*df['day']/31)\n",
    "    df['day_cos']   = np.cos(2*np.pi*df['day']/31)\n",
    "\n",
    "    df['temp_range'] = df['TX'] - df['TN']\n",
    "\n",
    "    def month_to_season(m):\n",
    "        if m in [12,1,2]: return 1\n",
    "        elif m in [3,4,5]: return 2\n",
    "        elif m in [6,7,8]: return 3\n",
    "        else: return 4\n",
    "    df['season'] = df['month'].apply(month_to_season)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = add_safe_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b28db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['TANGGAL'] < '2024-01-01']\n",
    "val   = df[(df['TANGGAL'] >= '2024-01-01') & (df['TANGGAL'] < '2025-01-01')]\n",
    "test  = df[df['TANGGAL'] >= '2025-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa4024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leakage_safe_lags(train, val, test):\n",
    "    # Digabung, tapi rolling hanya dari bagian TRAIN\n",
    "    full = pd.concat([train, val, test], axis=0)\n",
    "\n",
    "    full['RR_lag1']  = full['RR'].shift(1)\n",
    "    full['RR_lag7']  = full['RR'].shift(7)\n",
    "    full['TAVG_lag1'] = full['TAVG'].shift(1)\n",
    "\n",
    "    full['RR_diff1'] = full['RR'] - full['RR_lag1']\n",
    "    full['RH_diff1'] = full['RH_AVG'] - full['RH_AVG'].shift(1)\n",
    "\n",
    "    full['RR_7d']  = full['RR'].rolling(7).mean()\n",
    "    full['RR_30d'] = full['RR'].rolling(30).mean()\n",
    "\n",
    "    full['Rain_7d_count'] = full['RR'].apply(lambda x: 1 if x > 0 else 0).rolling(7).sum()\n",
    "\n",
    "    # Setelah fitur selesai → split kembali\n",
    "    train2 = full.loc[train.index]\n",
    "    val2   = full.loc[val.index]\n",
    "    test2  = full.loc[test.index]\n",
    "\n",
    "    return train2, val2, test2\n",
    "\n",
    "train, val, test = add_leakage_safe_lags(train, val, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdf7a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "val   = val.dropna()\n",
    "test  = test.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4117278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'TN','TX','TAVG','RH_AVG','SS','FF_X','DDD_X','FF_AVG','DDD_CAR',\n",
    "    'RR_lag1','RR_lag7','TAVG_lag1','RR_diff1','RH_diff1',\n",
    "    'RR_7d','RR_30d','Rain_7d_count',\n",
    "    'month_sin','month_cos','day_sin','day_cos','temp_range','season'\n",
    "]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train['RR']\n",
    "\n",
    "X_val = val[features]\n",
    "y_val = val['RR']\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test['RR']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF MAE: 0.5902544461178755\n",
      "RF MAE: 0.5902544461178755\n",
      "RF RMSE: 1.488355336630911\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=20,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_val_scaled)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_val, pred_rf)      # default mengembalikan MSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RF MAE:\", mean_absolute_error(y_val, pred_rf))\n",
    "print(\"RF RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec140109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB MAE: 0.6747502367283095\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_xgb = xgb.predict(X_val_scaled)\n",
    "\n",
    "print(\"XGB MAE:\", mean_absolute_error(y_val, pred_xgb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape → (samples, timesteps, features)\n",
    "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_val_lstm   = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45232150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 289.8715 - val_loss: 218.3772\n",
      "Epoch 2/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.8733 - val_loss: 118.1704\n",
      "Epoch 3/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.7682 - val_loss: 55.3890\n",
      "Epoch 4/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.6580 - val_loss: 24.9929\n",
      "Epoch 5/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.2924 - val_loss: 14.4514\n",
      "Epoch 6/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.9970 - val_loss: 9.8083\n",
      "Epoch 7/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.8809 - val_loss: 7.0366\n",
      "Epoch 8/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 21.0537 - val_loss: 5.2750\n",
      "Epoch 9/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.4472 - val_loss: 4.0940\n",
      "Epoch 10/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.8767 - val_loss: 3.5153\n",
      "Epoch 11/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 14.8430 - val_loss: 3.4517\n",
      "Epoch 12/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 14.6977 - val_loss: 3.2284\n",
      "Epoch 13/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9712 - val_loss: 2.4985\n",
      "Epoch 14/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1346 - val_loss: 2.2219\n",
      "Epoch 15/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 12.5721 - val_loss: 1.9293\n",
      "Epoch 16/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.8944 - val_loss: 1.7178\n",
      "Epoch 17/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7303 - val_loss: 2.6085\n",
      "Epoch 18/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2981 - val_loss: 2.1939\n",
      "Epoch 19/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9710 - val_loss: 3.4133\n",
      "Epoch 20/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8529 - val_loss: 2.1433\n",
      "Epoch 21/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3840 - val_loss: 0.9920\n",
      "Epoch 22/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4360 - val_loss: 1.7259\n",
      "Epoch 23/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2597 - val_loss: 2.3619\n",
      "Epoch 24/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5814 - val_loss: 2.3608\n",
      "Epoch 25/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6939 - val_loss: 2.3713\n",
      "Epoch 26/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5792 - val_loss: 2.3534\n",
      "Epoch 27/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.0085 - val_loss: 3.2188\n",
      "Epoch 28/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4542 - val_loss: 2.3697\n",
      "Epoch 29/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1505 - val_loss: 2.3606\n",
      "Epoch 30/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6643 - val_loss: 1.9749\n",
      "Epoch 31/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3146 - val_loss: 2.6339\n",
      "Epoch 32/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9691 - val_loss: 1.8773\n",
      "Epoch 33/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0595 - val_loss: 1.3846\n",
      "Epoch 34/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4735 - val_loss: 1.2610\n",
      "Epoch 35/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8493 - val_loss: 2.4407\n",
      "Epoch 36/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3896 - val_loss: 2.2002\n",
      "Epoch 37/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8100 - val_loss: 1.6020\n",
      "Epoch 38/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.7131 - val_loss: 2.9754\n",
      "Epoch 39/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9986 - val_loss: 2.3001\n",
      "Epoch 40/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0435 - val_loss: 2.8553\n",
      "Epoch 41/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.5539 - val_loss: 1.8886\n",
      "Epoch 42/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.6905 - val_loss: 1.2790\n",
      "Epoch 43/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2393 - val_loss: 1.6460\n",
      "Epoch 44/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4633 - val_loss: 1.3255\n",
      "Epoch 45/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7054 - val_loss: 0.9827\n",
      "Epoch 46/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5245 - val_loss: 0.8808\n",
      "Epoch 47/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1784 - val_loss: 1.3511\n",
      "Epoch 48/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8816 - val_loss: 2.5349\n",
      "Epoch 49/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2580 - val_loss: 1.7020\n",
      "Epoch 50/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5156 - val_loss: 1.1054\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "LSTM MAE: 0.5277772420866242\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=False, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    validation_data=(X_val_lstm, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "pred_lstm = model.predict(X_val_lstm)\n",
    "print(\"LSTM MAE:\", mean_absolute_error(y_val, pred_lstm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e1aec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TANGGAL</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>RH_AVG</th>\n",
       "      <th>RR</th>\n",
       "      <th>SS</th>\n",
       "      <th>FF_X</th>\n",
       "      <th>DDD_X</th>\n",
       "      <th>FF_AVG</th>\n",
       "      <th>DDD_CAR</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>temp_range</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>27.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>27.2</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.988468</td>\n",
       "      <td>0.151428</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>26.6</td>\n",
       "      <td>29.6</td>\n",
       "      <td>27.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.998717</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>26.2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>30.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>-0.250653</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>27.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.897805</td>\n",
       "      <td>-0.440394</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TANGGAL    TN    TX  TAVG  RH_AVG    RR   SS  FF_X  DDD_X  FF_AVG  \\\n",
       "3978 2025-11-06  27.2  33.2  29.4    71.0   0.0  2.4     4    260       2   \n",
       "3979 2025-11-07  27.2  34.2  29.4    75.0   0.0  2.3     3    280       1   \n",
       "3980 2025-11-08  26.6  29.6  27.5    81.0   0.0  6.0     4    250       2   \n",
       "3981 2025-11-09  26.2  34.5  30.8    66.0  12.4  4.5     5    240       3   \n",
       "3982 2025-11-10  27.4  33.7  29.9    68.0   0.0  6.7     5    220       2   \n",
       "\n",
       "      DDD_CAR  month  day  month_sin  month_cos   day_sin   day_cos  \\\n",
       "3978      225     11    6       -0.5   0.866025  0.937752  0.347305   \n",
       "3979        0     11    7       -0.5   0.866025  0.988468  0.151428   \n",
       "3980      225     11    8       -0.5   0.866025  0.998717 -0.050649   \n",
       "3981      225     11    9       -0.5   0.866025  0.968077 -0.250653   \n",
       "3982      225     11   10       -0.5   0.866025  0.897805 -0.440394   \n",
       "\n",
       "      temp_range  season  \n",
       "3978         6.0       4  \n",
       "3979         7.0       4  \n",
       "3980         3.0       4  \n",
       "3981         8.3       4  \n",
       "3982         6.3       4  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0ecec01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 23)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m target_date = \u001b[33m'\u001b[39m\u001b[33m2025-11-11\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m row = test[test[\u001b[33m'\u001b[39m\u001b[33mTANGGAL\u001b[39m\u001b[33m'\u001b[39m] == target_date]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m row_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 3 model predictions\u001b[39;00m\n\u001b[32m      7\u001b[39m pred_rf_5  = rf.predict(row_scaled)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1075\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1072\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1074\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1087\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 23)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "target_date = '2025-11-11'\n",
    "row = test[test['TANGGAL'] == target_date]\n",
    "\n",
    "row_scaled = scaler.transform(row[features])\n",
    "\n",
    "# 3 model predictions\n",
    "pred_rf_5  = rf.predict(row_scaled)[0]\n",
    "pred_xgb_5 = xgb.predict(row_scaled)[0]\n",
    "pred_lstm_5 = model.predict(row_scaled.reshape(1,1,-1))[0][0]\n",
    "\n",
    "print(\"Prediksi Curah Hujan 5 Des 2025\")\n",
    "print(\"RF  :\", pred_rf_5)\n",
    "print(\"XGB :\", pred_xgb_5)\n",
    "print(\"LSTM:\", pred_lstm_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c0ca604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TANGGAL    TN    TX  TAVG  RH_AVG   RR   SS  FF_X  DDD_X  FF_AVG  ...  \\\n",
      "3982 2025-11-10  27.4  33.7  29.9    68.0  0.0  6.7     5    220       2  ...   \n",
      "\n",
      "      temp_range  season  RR_lag1  RR_lag7  TAVG_lag1  RR_diff1  RH_diff1  \\\n",
      "3982         6.3       4     12.4      0.0       30.8     -12.4       2.0   \n",
      "\n",
      "         RR_7d  RR_30d  Rain_7d_count  \n",
      "3982  2.371429    8.27            2.0  \n",
      "\n",
      "[1 rows x 27 columns]\n",
      "Jumlah baris: 1\n"
     ]
    }
   ],
   "source": [
    "target_date = '2025-11-10'\n",
    "row = test[test['TANGGAL'] == target_date]\n",
    "\n",
    "print(row)\n",
    "print(\"Jumlah baris:\", len(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212525b3",
   "metadata": {},
   "source": [
    "# Predict Future (Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d62a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future_row(df, future_date):\n",
    "    \"\"\"\n",
    "    df          : dataframe lengkap setelah feature engineering aman (date features, season, etc)\n",
    "    future_date : string 'YYYY-MM-DD'\n",
    "    \"\"\"\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "\n",
    "    # --- 1. Ambil 30 hari terakhir\n",
    "    last_30 = df.tail(30).copy()\n",
    "\n",
    "    # --- 2. Ambil hari terakhir sebagai baseline future\n",
    "    last_row = df.iloc[-1].copy()\n",
    "\n",
    "    # --- 3. Buat row baru\n",
    "    future_row = last_row.copy()\n",
    "    future_row['TANGGAL'] = future_date\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 4. DATE FEATURES\n",
    "    # ------------------------------------------\n",
    "    future_row['month'] = future_date.month\n",
    "    future_row['day']   = future_date.day\n",
    "\n",
    "    # Cyclic encoding\n",
    "    future_row['month_sin'] = np.sin(2*np.pi * future_row['month'] / 12)\n",
    "    future_row['month_cos'] = np.cos(2*np.pi * future_row['month'] / 12)\n",
    "    future_row['day_sin']   = np.sin(2*np.pi * future_row['day'] / 31)\n",
    "    future_row['day_cos']   = np.cos(2*np.pi * future_row['day'] / 31)\n",
    "\n",
    "    # Temperature range\n",
    "    future_row['temp_range'] = future_row['TX'] - future_row['TN']\n",
    "\n",
    "    # Season\n",
    "    def month_to_season(m):\n",
    "        if m in [12,1,2]: return 1\n",
    "        if m in [3,4,5]: return 2\n",
    "        if m in [6,7,8]: return 3\n",
    "        return 4\n",
    "\n",
    "    future_row['season'] = month_to_season(future_row['month'])\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 5. Gabungkan 30 hari terakhir + 1 future\n",
    "    #    supaya rolling dan lag bisa dihitung\n",
    "    # ------------------------------------------\n",
    "    temp = pd.concat([last_30, pd.DataFrame([future_row])], ignore_index=True)\n",
    "\n",
    "    # LAG\n",
    "    temp['RR_lag1']   = temp['RR'].shift(1)\n",
    "    temp['RR_lag7']   = temp['RR'].shift(7)\n",
    "    temp['TAVG_lag1'] = temp['TAVG'].shift(1)\n",
    "\n",
    "    temp['RR_diff1'] = temp['RR'] - temp['RR_lag1']\n",
    "    temp['RH_diff1'] = temp['RH_AVG'] - temp['RH_AVG'].shift(1)\n",
    "\n",
    "    # Rolling\n",
    "    temp['RR_7d']  = temp['RR'].rolling(7).mean()\n",
    "    temp['RR_30d'] = temp['RR'].rolling(30).mean()\n",
    "\n",
    "    # Rain count 7 days\n",
    "    temp['Rain_7d_count'] = temp['RR'].apply(lambda x: 1 if x > 0 else 0).rolling(7).sum()\n",
    "\n",
    "    # Ambil row terakhir = future row siap pakai\n",
    "    future_ready = temp.iloc[-1:]\n",
    "\n",
    "    return future_ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "237fe4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(df, future_date, features, scaler, rf, xgb, lstm_model):\n",
    "    # buat fitur untuk future date\n",
    "    future_row = create_future_row(df, future_date)\n",
    "\n",
    "    # scaling\n",
    "    future_scaled = scaler.transform(future_row[features])\n",
    "\n",
    "    # RF\n",
    "    pred_rf = rf.predict(future_scaled)[0]\n",
    "\n",
    "    # XGB\n",
    "    pred_xgb = xgb.predict(future_scaled)[0]\n",
    "\n",
    "    # LSTM (reshape 3D)\n",
    "    pred_lstm = lstm_model.predict(future_scaled.reshape(1,1,-1))[0][0]\n",
    "\n",
    "    return {\n",
    "        \"date\": future_date,\n",
    "        \"RF\": pred_rf,\n",
    "        \"XGB\": pred_xgb,\n",
    "        \"LSTM\": pred_lstm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca68db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Prediksi RR pada 2025-11-11\n",
      "Random Forest : 1.2532167459646977e-06\n",
      "XGBoost       : -0.033519138\n",
      "LSTM          : 0.23861872\n"
     ]
    }
   ],
   "source": [
    "future_date = \"2025-11-11\"\n",
    "\n",
    "result = predict_future(\n",
    "    df=df,\n",
    "    future_date=future_date,\n",
    "    features=features,\n",
    "    scaler=scaler,\n",
    "    rf=rf,\n",
    "    xgb=xgb,\n",
    "    lstm_model=model\n",
    ")\n",
    "\n",
    "print(\"Prediksi RR pada\", result[\"date\"])\n",
    "print(\"Random Forest :\", result[\"RF\"])\n",
    "print(\"XGBoost       :\", result[\"XGB\"])\n",
    "print(\"LSTM          :\", result[\"LSTM\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453324a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
