{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21d47f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f1b8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb73c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('updated_dataset_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6f215d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad2c8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"updated_dataset_final.xlsx\", parse_dates=['Tanggal']) #parse = untuk ngubah kolom Tanggal jadi datetime\n",
    "df = df.sort_values('Tanggal')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dd391d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4020 entries, 0 to 4019\n",
      "Data columns (total 11 columns):\n",
      " #   Column                              Non-Null Count  Dtype         \n",
      "---  ------                              --------------  -----         \n",
      " 0   Tanggal                             4020 non-null   datetime64[ns]\n",
      " 1   Temperatur Minimum                  4020 non-null   float64       \n",
      " 2   Temperatur Maksimum                 4020 non-null   float64       \n",
      " 3   Temperatur Rata-rata                4020 non-null   float64       \n",
      " 4   Kelembapan Rata-rata                4020 non-null   float64       \n",
      " 5   Curah Hujan (mm)                    4020 non-null   float64       \n",
      " 6   Lamanya Penyinaran Matahari         4020 non-null   float64       \n",
      " 7   Kecepatan Angin Maksimum            4020 non-null   int64         \n",
      " 8   Arah Angin Saat Kecepatan Maksimum  4020 non-null   int64         \n",
      " 9   Kecepatan Angin Rata-rata           4020 non-null   int64         \n",
      " 10  Arah Angin Terbanyak (°)            4020 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(4)\n",
      "memory usage: 345.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98677859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_safe_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Extract month and day in Tanggal column\n",
    "    df['month'] = df['Tanggal'].dt.month\n",
    "    df['day']   = df['Tanggal'].dt.day\n",
    "\n",
    "    # Create coordinat cos dan sin menggunakan rumus  \n",
    "    df['month_sin'] = np.sin(2*np.pi*df['month']/12)\n",
    "    df['month_cos'] = np.cos(2*np.pi*df['month']/12)\n",
    "    df['day_sin']   = np.sin(2*np.pi*df['day']/31)\n",
    "    df['day_cos']   = np.cos(2*np.pi*df['day']/31)\n",
    "\n",
    "    df['temp_range'] = df['Temperatur Maksimum'] - df['Temperatur Minimum']\n",
    "\n",
    "    return df\n",
    "\n",
    "df = add_safe_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4b28db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Tanggal'] < '2024-01-01']\n",
    "val   = df[(df['Tanggal'] >= '2024-01-01') & (df['Tanggal'] < '2025-01-01')]\n",
    "test  = df[df['Tanggal'] >= '2025-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aa4024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leakage_safe_lags(train, val, test):\n",
    "    # Gabung supaya index tetap utuh (kemudian akan di-slice kembali)\n",
    "    full = pd.concat([train, val, test], axis=0).sort_index()\n",
    "\n",
    "    # --- LAG features (aman) ---\n",
    "    full['Curah Hujan (mm)_lag1']  = full['Curah Hujan (mm)'].shift(1)\n",
    "    full['Curah Hujan (mm)_lag2']  = full['Curah Hujan (mm)'].shift(2)\n",
    "    full['Curah Hujan (mm)_lag3']  = full['Curah Hujan (mm)'].shift(3)\n",
    "    full['Curah Hujan (mm)_lag7']  = full['Curah Hujan (mm)'].shift(7)\n",
    "    full['Temperatur Rata-rata_lag1'] = full['Temperatur Rata-rata'].shift(1)\n",
    "\n",
    "    # --- Differencing (aman) ---\n",
    "    full['Curah Hujan (mm)_diff1'] = full['Curah Hujan (mm)'] - full['Curah Hujan (mm)_lag1']\n",
    "    full['RH_diff1'] = full['Kelembapan Rata-rata'] - full['Kelembapan Rata-rata'].shift(1)\n",
    "\n",
    "    # --- Rolling features (SAFE: shift first, then rolling on past values) ---\n",
    "    # buat seri hujan yang hanya berisi nilai sampai t-1 (tidak termasuk t)\n",
    "    rain_past = full['Curah Hujan (mm)'].shift(1)\n",
    "\n",
    "    full['Curah Hujan (mm)_7d']  = rain_past.rolling(window=7, min_periods=1).mean()\n",
    "    full['Curah Hujan (mm)_14d'] = rain_past.rolling(window=14, min_periods=1).mean()\n",
    "    full['Curah Hujan (mm)_30d'] = rain_past.rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "    # Rain count: ubah ke indikator lalu shift lalu rolling sum\n",
    "    rain_indicator_past = (full['Curah Hujan (mm)'] > 0).astype(int).shift(1)\n",
    "    full['Rain_7d_count'] = rain_indicator_past.rolling(window=7, min_periods=1).sum()\n",
    "\n",
    "    # Jika ingin, bisa juga tambahkan rolling std, max, dll dengan pola yang sama:\n",
    "    # full['Curah Hujan (mm)_7d_std'] = rain_past.rolling(7, min_periods=1).std()\n",
    "\n",
    "    # --- Kembalikan ke split semula ---\n",
    "    train2 = full.loc[train.index].copy()\n",
    "    val2   = full.loc[val.index].copy()\n",
    "    test2  = full.loc[test.index].copy()\n",
    "\n",
    "    return train2, val2, test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a61a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, val2, test2 = add_leakage_safe_lags(train, val, test)\n",
    "\n",
    "train2 = train2.dropna()\n",
    "val2   = val2.dropna()\n",
    "test2  = test2.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117278d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Curah Hujan (mm)_lag1', 'Curah Hujan (mm)_lag2', 'Curah Hujan (mm)_lag3', 'Curah Hujan (mm)_lag7', 'Temperatur Rata-rata_lag1', 'Curah Hujan (mm)_diff1', 'RH_diff1', 'Curah Hujan (mm)_7d', 'Curah Hujan (mm)_14d', 'Curah Hujan (mm)_30d', 'Rain_7d_count'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      1\u001b[39m features = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTemperatur Minimum\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mTemperatur Maksimum\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mTemperatur Rata-rata\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mKelembapan Rata-rata\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mLamanya Penyinaran Matahari\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mKecepatan Angin Maksimum\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mArah Angin Saat Kecepatan Maksimum\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mKecepatan Angin Rata-rata\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mArah Angin Terbanyak (°)\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_lag1\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_lag2\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_lag3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_lag7\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mTemperatur Rata-rata_lag1\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_diff1\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mRH_diff1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_7d\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_14d\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCurah Hujan (mm)_30d\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mRain_7d_count\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmonth_sin\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mmonth_cos\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mday_sin\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mday_cos\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mtemp_range\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# X_train = train2[features]\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# #y_train = train2['Curah Hujan (mm)']\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# #y_test = test2['Curah Hujan (mm)']\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# y_test  = np.log1p(test['Curah Hujan (mm)'])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m X_train = \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m X_val   = val[features]\n\u001b[32m     28\u001b[39m X_test  = test[features]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Curah Hujan (mm)_lag1', 'Curah Hujan (mm)_lag2', 'Curah Hujan (mm)_lag3', 'Curah Hujan (mm)_lag7', 'Temperatur Rata-rata_lag1', 'Curah Hujan (mm)_diff1', 'RH_diff1', 'Curah Hujan (mm)_7d', 'Curah Hujan (mm)_14d', 'Curah Hujan (mm)_30d', 'Rain_7d_count'] not in index\""
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'Temperatur Minimum','Temperatur Maksimum','Temperatur Rata-rata','Kelembapan Rata-rata','Lamanya Penyinaran Matahari','Kecepatan Angin Maksimum','Arah Angin Saat Kecepatan Maksimum','Kecepatan Angin Rata-rata','Arah Angin Terbanyak (°)',\n",
    "    'Curah Hujan (mm)_lag1','Curah Hujan (mm)_lag2','Curah Hujan (mm)_lag3', 'Curah Hujan (mm)_lag7','Temperatur Rata-rata_lag1','Curah Hujan (mm)_diff1','RH_diff1',\n",
    "    'Curah Hujan (mm)_7d', 'Curah Hujan (mm)_14d','Curah Hujan (mm)_30d','Rain_7d_count',\n",
    "    'month_sin','month_cos','day_sin','day_cos','temp_range'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "X_train = train2[features]\n",
    "#y_train = train2['Curah Hujan (mm)']\n",
    "\n",
    "y_train = np.log1p(train['Curah Hujan (mm)'])\n",
    "\n",
    "\n",
    "\n",
    "X_val = val2[features]\n",
    "#y_val = val2['Curah Hujan (mm)']\n",
    "y_val   = np.log1p(val['Curah Hujan (mm)'])\n",
    "\n",
    "\n",
    "X_test = test2[features]\n",
    "#y_test = test2['Curah Hujan (mm)']\n",
    "y_test  = np.log1p(test['Curah Hujan (mm)'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f3122",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3296, 3303]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m rf = RandomForestRegressor(\n\u001b[32m      2\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m      3\u001b[39m     max_depth=\u001b[32m20\u001b[39m,\n\u001b[32m      4\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m pred_rf = rf.predict(X_val_scaled)\n\u001b[32m     10\u001b[39m pred_rf = np.expm1(pred_rf_log)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m X = check_array(\n\u001b[32m   1369\u001b[39m     X,\n\u001b[32m   1370\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1382\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1383\u001b[39m )\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [3296, 3303]"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=20,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_val_scaled)\n",
    "\n",
    "pred_rf = np.expm1(pred_rf_log)\n",
    "y_val_real = np.expm1(y_val)\n",
    "\n",
    "# Perbaikan di sini: mean_squared_error\n",
    "print(\"RF MAE:\", mean_absolute_error(y_val_real, pred_rf))\n",
    "print(\"RF RMSE:\", np.sqrt(mean_squared_error(y_val_real, pred_rf)))\n",
    "\n",
    "# Output Anda:\n",
    "# RF MAE: 0.5942667449238894\n",
    "# RF RMSE: 1.500483658715626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec140109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB MAE: 0.8336703617967682\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_xgb = xgb.predict(X_val_scaled)\n",
    "\n",
    "print(\"XGB MAE:\", mean_absolute_error(y_val, pred_xgb))\n",
    "\n",
    "#XGB MAE: 0.7026166778040924\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape → (samples, timesteps, features)\n",
    "# X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "# X_val_lstm   = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45232150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo E15\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 297.0454 - val_loss: 221.7646\n",
      "Epoch 2/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.5955 - val_loss: 116.0461\n",
      "Epoch 3/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.6487 - val_loss: 49.1876\n",
      "Epoch 4/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.1571 - val_loss: 18.9748\n",
      "Epoch 5/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.0752 - val_loss: 11.7287\n",
      "Epoch 6/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.0323 - val_loss: 9.3131\n",
      "Epoch 7/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.6186 - val_loss: 6.7704\n",
      "Epoch 8/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.3243 - val_loss: 5.4069\n",
      "Epoch 9/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9012 - val_loss: 4.7761\n",
      "Epoch 10/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.0020 - val_loss: 4.4792\n",
      "Epoch 11/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.5528 - val_loss: 3.5216\n",
      "Epoch 12/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.5016 - val_loss: 3.8234\n",
      "Epoch 13/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0312 - val_loss: 2.6378\n",
      "Epoch 14/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1803 - val_loss: 3.1944\n",
      "Epoch 15/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3466 - val_loss: 2.1865\n",
      "Epoch 16/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10.2749 - val_loss: 2.3529\n",
      "Epoch 17/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6322 - val_loss: 2.6530\n",
      "Epoch 18/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0306 - val_loss: 1.8766\n",
      "Epoch 19/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5524 - val_loss: 2.1542\n",
      "Epoch 20/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1378 - val_loss: 2.6076\n",
      "Epoch 21/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9576 - val_loss: 3.1710\n",
      "Epoch 22/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7773 - val_loss: 2.8070\n",
      "Epoch 23/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.6185 - val_loss: 3.3921\n",
      "Epoch 24/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8099 - val_loss: 4.7220\n",
      "Epoch 25/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.2293 - val_loss: 2.0371\n",
      "Epoch 26/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.1133 - val_loss: 2.7189\n",
      "Epoch 27/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6677 - val_loss: 3.1786\n",
      "Epoch 28/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0248 - val_loss: 2.8390\n",
      "Epoch 29/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4775 - val_loss: 3.1454\n",
      "Epoch 30/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3140 - val_loss: 3.3549\n",
      "Epoch 31/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4146 - val_loss: 2.1816\n",
      "Epoch 32/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0781 - val_loss: 1.8942\n",
      "Epoch 33/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2242 - val_loss: 1.7075\n",
      "Epoch 34/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.1290 - val_loss: 2.0895\n",
      "Epoch 35/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.2742 - val_loss: 2.5905\n",
      "Epoch 36/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9895 - val_loss: 1.8993\n",
      "Epoch 37/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9875 - val_loss: 2.1703\n",
      "Epoch 38/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2430 - val_loss: 1.5821\n",
      "Epoch 39/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.4665 - val_loss: 3.5774\n",
      "Epoch 40/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4525 - val_loss: 1.5661\n",
      "Epoch 41/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.7134 - val_loss: 2.0173\n",
      "Epoch 42/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.6453 - val_loss: 1.5829\n",
      "Epoch 43/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.7010 - val_loss: 3.3422\n",
      "Epoch 44/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.7801 - val_loss: 1.6674\n",
      "Epoch 45/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.6949 - val_loss: 0.9988\n",
      "Epoch 46/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3931 - val_loss: 1.3204\n",
      "Epoch 47/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7515 - val_loss: 1.1179\n",
      "Epoch 48/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.3006 - val_loss: 1.4777\n",
      "Epoch 49/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4633 - val_loss: 1.3382\n",
      "Epoch 50/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.5063 - val_loss: 2.0081\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "LSTM MAE: 0.6689252107289971\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#     LSTM(64, return_sequences=False, input_shape=(1, X_train_scaled.shape[1])),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "\n",
    "# # Perbaikan: parameter 'loss'\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train_lstm, y_train,\n",
    "#     validation_data=(X_val_lstm, y_val),\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# pred_lstm = model.predict(X_val_lstm)\n",
    "\n",
    "# # Perbaikan: fungsi mean_absolute_error\n",
    "# print(\"LSTM MAE:\", mean_absolute_error(y_val, pred_lstm))\n",
    "\n",
    "# # LSTM MAE: 0.550815572085602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# sns.kdeplot(y_train, label='Train Curah Hujan (mm)', fill=True)\n",
    "# sns.kdeplot(y_test, label='Test Curah Hujan (mm)', fill=True)\n",
    "# plt.title(\"Distribusi Target Train vs Test\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94828dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Perbaikan: variable 'corr' dan function '.corr()'\n",
    "# corr = pd.concat([X_train, y_train], axis=1).corr()\n",
    "\n",
    "# # Perbaikan: variable 'target_corr'\n",
    "# target_corr = corr['Curah Hujan (mm)'].sort_values(ascending=False)\n",
    "\n",
    "# print(\"Korelasi Fitur dengan Target:\")\n",
    "# print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# pred_train_rf = rf.predict(X_train_scaled)\n",
    "# pred_test_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# # Perbaikan fungsi mean_squared_error\n",
    "# train_rmse = np.sqrt(mean_squared_error(y_train, pred_train_rf))\n",
    "# test_rmse  = np.sqrt(mean_squared_error(y_test, pred_test_rf))\n",
    "\n",
    "# # Perbaikan fungsi mean_absolute_error\n",
    "# train_mae = mean_absolute_error(y_train, pred_train_rf)\n",
    "# test_mae  = mean_absolute_error(y_test, pred_test_rf)\n",
    "\n",
    "# print(\"RF Train RMSE:\", train_rmse)\n",
    "# print(\"RF Test RMSE :\", test_rmse)\n",
    "# print(\"RF Train MAE:\", train_mae)\n",
    "# print(\"RF Test MAE :\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6aec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,5))\n",
    "# plt.scatter(y_test, y_test - pred_test_rf, alpha=0.5, label=\"Test Residual\")\n",
    "# plt.scatter(y_train, y_train - pred_train_rf, alpha=0.5, label=\"Train Residual\")\n",
    "# plt.axhline(0, color='red', linestyle='--')\n",
    "# plt.xlabel(\"Actual Curah Hujan (mm)\")\n",
    "# plt.ylabel(\"Residual\")\n",
    "# plt.legend()\n",
    "# plt.title(\"Residual Train vs Test (RF)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212525b3",
   "metadata": {},
   "source": [
    "# Predict Future (Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_future_features(history_df, future_date):\n",
    "    history_df = history_df.copy()\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "\n",
    "    # Gunakan max window = 30 hari\n",
    "    last_30 = history_df.tail(30).copy()\n",
    "\n",
    "    base = history_df.iloc[-1].copy()\n",
    "    base['Tanggal'] = future_date\n",
    "\n",
    "    # --- Date features ---\n",
    "    base['month'] = future_date.month\n",
    "    base['day']   = future_date.day\n",
    "\n",
    "    base['month_sin'] = np.sin(2*np.pi*base['month']/12)\n",
    "    base['month_cos'] = np.cos(2*np.pi*base['month']/12)\n",
    "    base['day_sin']   = np.sin(2*np.pi*base['day']/31)\n",
    "    base['day_cos']   = np.cos(2*np.pi*base['day']/31)\n",
    "\n",
    "    base['temp_range'] = (\n",
    "        base['Temperatur Maksimum']\n",
    "        - base['Temperatur Minimum']\n",
    "    )\n",
    "\n",
    "    # Gabungkan histori + baris future (tanpa target future)\n",
    "    temp = pd.concat(\n",
    "        [last_30, pd.DataFrame([base])],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # --- LAG FEATURES (aman) ---\n",
    "    temp['Curah Hujan (mm)_lag1'] = temp['Curah Hujan (mm)'].shift(1)\n",
    "    temp['Curah Hujan (mm)_lag2'] = temp['Curah Hujan (mm)'].shift(2)\n",
    "    temp['Curah Hujan (mm)_lag3'] = temp['Curah Hujan (mm)'].shift(3)\n",
    "    temp['Curah Hujan (mm)_lag7'] = temp['Curah Hujan (mm)'].shift(7)\n",
    "\n",
    "    temp['Temperatur Rata-rata_lag1'] = temp['Temperatur Rata-rata'].shift(1)\n",
    "\n",
    "    temp['RH_diff1'] = (\n",
    "        temp['Kelembapan Rata-rata']\n",
    "        - temp['Kelembapan Rata-rata'].shift(1)\n",
    "    )\n",
    "\n",
    "    # --- ROLLING AMAN (SHIFT DULU!) ---\n",
    "    rain_past = temp['Curah Hujan (mm)'].shift(1)\n",
    "\n",
    "    temp['Curah Hujan (mm)_7d']  = rain_past.rolling(7).mean()\n",
    "    temp['Curah Hujan (mm)_14d'] = rain_past.rolling(14).mean()\n",
    "    temp['Curah Hujan (mm)_30d'] = rain_past.rolling(30).mean()\n",
    "\n",
    "    rain_ind_past = (temp['Curah Hujan (mm)'] > 0).astype(int).shift(1)\n",
    "    temp['Rain_7d_count'] = rain_ind_past.rolling(7).sum()\n",
    "\n",
    "    # ✅ Jangan buat diff curah hujan untuk future\n",
    "    temp['Curah Hujan (mm)_diff1'] = np.nan\n",
    "\n",
    "    return temp.iloc[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd792f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_7_days(\n",
    "    df,\n",
    "    start_date,\n",
    "    features,\n",
    "    scaler,\n",
    "    rf,\n",
    "    xgb,\n",
    "    lstm_model\n",
    "):\n",
    "    history = df.copy()\n",
    "    results = []\n",
    "\n",
    "    # Perbaikan: variable 'current_date'\n",
    "    current_date = pd.to_datetime(start_date)\n",
    "\n",
    "    for i in range(7):\n",
    "        # Perbaikan: variable 'current_date'\n",
    "        next_date = current_date + pd.Timedelta(days=1)\n",
    "\n",
    "        # Pastikan fungsi build_future_features sudah didefinisikan sebelumnya\n",
    "        future_row = build_future_features(history, next_date) \n",
    "        future_scaled = scaler.transform(future_row[features])\n",
    "\n",
    "        # Predictions\n",
    "        pred_rf  = np.expm1(rf.predict(future_scaled)[0])\n",
    "        pred_xgb = np.expm1(xgb.predict(future_scaled)[0])\n",
    "        pred_lstm = lstm_model.predict(\n",
    "            future_scaled.reshape(1,1,-1)\n",
    "        )[0][0]\n",
    "\n",
    "        # Ensemble simple (Rata-rata)\n",
    "        #pred_mean = np.mean([pred_rf, pred_xgb, pred_lstm])\n",
    "        pred_mean = np.mean([pred_rf, pred_xgb])\n",
    "        \n",
    "\n",
    "        results.append({\n",
    "            \"Tanggal\": next_date,\n",
    "            \"RF\": pred_rf,\n",
    "            \"XGB\": pred_xgb,\n",
    "            \"LSTM\": pred_lstm,\n",
    "            \"Ensemble\": pred_mean\n",
    "        })\n",
    "\n",
    "        # Append prediction untuk dipakai prediksi hari berikutnya (Recursive)\n",
    "        new_row = future_row.copy()\n",
    "        \n",
    "        # Bagian ini TETAP, karena ini nama kolom di Dataframe\n",
    "        new_row['Curah Hujan (mm)'] = pred_mean   \n",
    "        \n",
    "        history = pd.concat([history, new_row], ignore_index=True)\n",
    "\n",
    "        # Perbaikan: variable 'current_date'\n",
    "        current_date = next_date\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "     Tanggal        RF         XGB      LSTM   Ensemble\n",
      "0 2025-12-08  0.000000  109.366722  0.316322  36.561015\n",
      "1 2025-12-09  1.199116  125.959335  0.316322  42.491591\n",
      "2 2025-12-10  1.445437  128.501709  0.316322  43.421156\n",
      "3 2025-12-11  1.639630  142.135361  0.316322  48.030437\n",
      "4 2025-12-12  2.024077  132.723038  0.316322  45.021145\n",
      "5 2025-12-13  2.230200  137.656097  0.316322  46.734206\n",
      "6 2025-12-14  2.495690  139.025757  0.316322  47.279256\n"
     ]
    }
   ],
   "source": [
    "future_7d = forecast_7_days(\n",
    "    df=df,\n",
    "    start_date=\"2025-12-07\",\n",
    "    features=features,\n",
    "    scaler=scaler,\n",
    "    rf=rf,\n",
    "    xgb=xgb,\n",
    "    lstm_model=model\n",
    ")\n",
    "\n",
    "print(future_7d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
